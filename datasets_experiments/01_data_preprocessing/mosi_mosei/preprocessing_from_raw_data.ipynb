{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Preprocessing\n",
    "\n",
    "This notebook loads the raw data from the [MultiBench package](https://github.com/pliang279/MultiBench/tree/main), including datasets such as [MOSI](https://drive.google.com/drive/folders/1uEK737LXB9jAlf9kyqRs6B9N6cDncodq) and [MOSEI](https://drive.google.com/drive/folders/1A_hTmifi824gypelGobgl2M-5Rw9VWHv). The initial preprocessing focuses on simplifying and structuring the data to ensure compatibility with the latent representation models. Key transformations include averaging specific views to generate vector representations for each text segment.\n",
    "\n",
    "- **Process Overview**: read *_raw.pkl files and transform them into *_transformed.pkl files, preparing data for the next stages\n",
    "- **Note**: Text data is represented in GloVe embeddings; to convert these back into words, refer to the `preprocessin_transform_from_glove` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_raw(dataset_raw, funny=False):\n",
    "    \n",
    "    view_text = []\n",
    "    view_vision = []\n",
    "    view_audio = []\n",
    "    labels = []\n",
    "    index = []\n",
    "    data_split = []\n",
    "    data_keys = list(dataset_raw.keys())\n",
    "\n",
    "    for set_ind in range(len(data_keys)):\n",
    "        data_set = data_keys[set_ind]\n",
    "\n",
    "        N = len(dataset_raw[data_set]['text'])\n",
    "        \n",
    "        zeros_set = np.abs(dataset_raw[data_set]['text']).sum(axis=2)\n",
    "        \n",
    "        for i in tqdm(range(N)):\n",
    "            zeros_set_i = zeros_set[i,:]\n",
    "\n",
    "            zeros_index_i = np.where(np.cumsum(zeros_set_i) == 0)[0]\n",
    "\n",
    "            if len(zeros_index_i) == 0:\n",
    "                first_meaningful_i = 0\n",
    "            else:\n",
    "                first_meaningful_i = zeros_index_i[-1] + 1\n",
    "\n",
    "            text_i = dataset_raw[data_set]['text'][i,first_meaningful_i:,:]\n",
    "\n",
    "            vision_i = dataset_raw[data_set]['vision'][i,first_meaningful_i:,:].mean(axis=0)\n",
    "            audio_i = dataset_raw[data_set]['audio'][i,first_meaningful_i:,:].mean(axis=0)\n",
    "\n",
    "            view_text.append(text_i)\n",
    "            view_vision.append(vision_i)\n",
    "            view_audio.append(audio_i)\n",
    "\n",
    "        labels.append(dataset_raw[data_set]['labels'])\n",
    "        index.append(dataset_raw[data_set]['id'])\n",
    "\n",
    "        data_split.append(np.repeat(data_set, N))\n",
    "\n",
    "    if funny == False:\n",
    "        labels_dataset = np.concatenate(labels)[:,0,:]\n",
    "    else: \n",
    "        labels_dataset = np.concatenate(labels)[:,:]\n",
    "\n",
    "    dataset = {\n",
    "        'M0': np.vstack(view_vision),\n",
    "        'M1': np.vstack(view_audio),\n",
    "        'M2': view_text,\n",
    "        'labels': labels_dataset,\n",
    "        'index': np.concatenate(index),\n",
    "        'train_val_test': np.concatenate(data_split)\n",
    "    }\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOSEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets_download/MOSEI/mosei_raw.pkl', \"rb\") as input_file:\n",
    "    dataset_raw = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = transform_data_raw(dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['M0'].shape, dataset['M1'].shape, len(dataset['M2']), dataset['labels'].shape, dataset['index'].shape, dataset['train_val_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets_download/MOSEI/MOSEI_transformed.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets_download/MOSI/mosi_raw.pkl', \"rb\") as input_file:\n",
    "    dataset_raw = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = transform_data_raw(dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['M0'].shape, dataset['M1'].shape, len(dataset['M2']), dataset['labels'].shape, dataset['index'].shape, dataset['train_val_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets_download/MOSI/MOSI_transformed.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_multibench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
