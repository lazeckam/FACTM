{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming GloVe Embeddings to Words\n",
    "\n",
    "In this section, we convert text modality data from GloVe embeddings, where each word is represented as a 300-dimensional vector, back into readable text. The GloVe word embeddings can be downloaded from the official GloVe project page:  [GloVe](https://nlp.stanford.edu/projects/glove/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/MultiBench/datasets_download'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = []\n",
    "glove_dict = []\n",
    "\n",
    "count = 0\n",
    "words_dic = []\n",
    "glove_dic = []\n",
    "\n",
    "file_name = './glove_representation/glove.840B.300d.txt'\n",
    "\n",
    "txt_file = open(file_name)\n",
    "\n",
    "for line in tqdm(txt_file):\n",
    "    count += 1\n",
    "    tmp0 = line.split()\n",
    "    start_index = len(tmp0) - 300\n",
    "    words_dict.append(''.join(tmp0[0:start_index]))\n",
    "    glove_dict.append(np.array(tmp0[start_index:(start_index+5)]).astype('float'))\n",
    "\n",
    "txt_file.close()\n",
    "glove_dict = np.array(glove_dict)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path+'/'+str('MOSI/MOSI_transformed')+'.pkl', \"rb\") as input_file:\n",
    "    dataset = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_modality_glove = dataset['M2']\n",
    "text_modality = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(text_modality_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = np.array([[1000, 1000, 1000, 1000, 1000]])\n",
    "new_words = ['word_wrong']\n",
    "where_new_words = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(N)):\n",
    "\n",
    "    words_tmp = text_modality_glove[i][:,0:5]\n",
    "\n",
    "    text_tmp=\"\"\n",
    "\n",
    "    for j in range(words_tmp.shape[0]):\n",
    "        \n",
    "        word_tmp = words_tmp[j,:]\n",
    "\n",
    "        distance_word_dict = np.sum((glove_dict - word_tmp)**2, axis=1)\n",
    "        indeces_tmp = np.where(distance_word_dict == np.min(distance_word_dict))[0]\n",
    "\n",
    "        # if too many fits\n",
    "        if np.sum(distance_word_dict <= np.min(distance_word_dict) + 1e-10) > 1:\n",
    "            print(\"Too many words fit glove rep.\")\n",
    "\n",
    "        if indeces_tmp.shape[0] > 1:\n",
    "            print(str(i)+\" \"+str(j) + \" more than one fits\")\n",
    "\n",
    "        index_tmp = indeces_tmp.astype('int')[0]\n",
    "\n",
    "        if np.sum((glove_dict[index_tmp,:] - word_tmp)**2) > 1e-5:\n",
    "            print(str(i)+\" \"+str(j)+\" not found in a dictionary \" + str(word_tmp))\n",
    "\n",
    "            distance_new_word_dict = np.sum((new_dict - word_tmp)**2, axis=1)\n",
    "            indeces_tmp = np.where(distance_new_word_dict == np.min(distance_new_word_dict))[0]\n",
    "\n",
    "            index_tmp = indeces_tmp.astype('int')[0]\n",
    "\n",
    "            if np.sum((new_dict[index_tmp,:] - word_tmp)**2) > 1e-5:\n",
    "                print(\"-- Adding new word\")\n",
    "                new_dict = np.vstack((new_dict, word_tmp))\n",
    "                new_words.append(\"WORD_\"+str(len(new_dict) - 2))\n",
    "                text_word_tmp = \"WORD_\"+str(len(new_dict) - 2)\n",
    "                where_new_words.append([[i, j]])\n",
    "            else:\n",
    "                print(\"--using already added words\")\n",
    "                text_word_tmp = new_words[index_tmp]\n",
    "        else:\n",
    "            text_word_tmp = words_dict[index_tmp]\n",
    "        \n",
    "        text_tmp = text_tmp+\" \"+text_word_tmp\n",
    "\n",
    "    text_modality.append(text_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_transformed/MOSI/text_modality.pkl', 'wb') as f:  \n",
    "    pickle.dump(text_modality, f, protocol=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOSEI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computed by `preprocessing_transform_from_glove_to_words_MOSEI.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_multibench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
